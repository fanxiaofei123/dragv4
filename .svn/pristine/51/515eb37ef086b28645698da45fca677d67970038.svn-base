source /etc/profile
for arg in $@
do
  key=`echo $arg|cut -d "=" -f 1`
  value=`echo $arg|cut -d "=" -f 2`
  if [ $key = "inputPath" ]
  then
  hdfsInputFile=$value
  elif [ $key = "tmpOutputData" ]
  then
  hdfsOutputData=$value
  elif [ $key = "tmpOutputModel" ]
  then
  hdfsOutputModel=$value
  elif [ $key = "scriptPath" ]
  then
  scriptPath=$value
  elif [ $key = "scriptName" ]
  then
  scriptName=$value
  elif [ $key = "function" ]
  then
  function=$value
  fi
done

#download hdfs data to local path
localScript=/tmp/custom/script/$scriptName
localData=/tmp/custom/data/`date +%N%S%N`.csv
localModel=/tmp/custom/model/`date +%N%S%N`.rds

if [ ! `hadoop fs -test -e $hdfsInputFile` ]
then
    hadoop fs -get $hdfsInputFile $localData
fi
if [ ! `hadoop fs -test -e $scriptPath` ]
then
    hadoop fs -get $scriptPath $localScript
fi

if [ $function = "R" ]
then
#run local R Script
#arg1-input data;arg2-input model
R -f $localScript --args $localData $localModel
elif [ $function = "python" ]
then
#run local python Script
#arg1-input data;arg2-input model
python3 $localScript $localData $localModel
#rm -f localScript
fi

#upload local file to hdfs
if [ -e $localData ]
then
    hadoop fs -copyFromLocal $localData $hdfsOutputData
    #rm -f $localData
fi
if [ -e $localModel ]
then
    hadoop fs -copyFromLocal $localModel $hdfsOutputModel
    #rm -f $localModel
fi